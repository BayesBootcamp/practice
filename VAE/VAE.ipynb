{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful links: \n",
    "* original paper http://arxiv.org/abs/1312.6114\n",
    "* helpful article \n",
    "   * https://jmetzen.github.io/2015-11-27/vae.html   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this seminalr we will train an autoencoder to model images of digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "image_h = 28\n",
    "image_w = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_gallery(images, h, w, n_row=3, n_col=6):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.5 * n_col, 1.7 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray, vmin=-1, vmax=1, interpolation='nearest')\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_gallery(mnist.train.images, image_h, image_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "\n",
    "Why to use all this complicated formulaes and regularizations, what is the need for variational inference? To analyze the difference, let's first train just an autoencoder on the data:\n",
    "\n",
    "<img src=\"Autoencoder_structure.png\" alt=\"Autoencoder\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_shape = [None, image_h*image_w]\n",
    "\n",
    "input_X = tf.placeholder(tf.float32, shape=input_shape, name='input_X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HU_encoder = 600 #you can play with this values\n",
    "HU_decoder = 600\n",
    "dimZ = 60 #considering digits reconstruction task, which size of representation seems reasonable?\n",
    "\n",
    "# define the network\n",
    "# use ReLU for hidden layers' activations\n",
    "# XavierUniform initialization for W\n",
    "# zero initialization for biases\n",
    "# it's also convenient to put sigmoid activation on output layer to get nice normalized pics\n",
    "\n",
    "\n",
    "with tf.variable_scope('encoder1'):\n",
    "    W = tf.get_variable(\"W\", shape=[input_shape[1], HU_encoder],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    b = tf.get_variable(\"b\", shape=[HU_encoder])\n",
    "    \n",
    "    enc = tf.nn.elu(tf.matmul(input_X, W) + b)\n",
    "    \n",
    "with tf.variable_scope('encoder2'):\n",
    "    W = tf.get_variable(\"W\", shape=[HU_encoder, dimZ],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    b = tf.get_variable(\"b\", shape=[dimZ])\n",
    "    \n",
    "    z = tf.matmul(enc, W) + b\n",
    "    \n",
    "with tf.variable_scope('decoder1'):\n",
    "    W = tf.get_variable(\"W\", shape=[dimZ, HU_decoder],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    b = tf.get_variable(\"b\", shape=[HU_decoder])\n",
    "    \n",
    "    dec = tf.nn.elu(tf.matmul(z, W) + b)\n",
    "    \n",
    "with tf.variable_scope('decoder2'):\n",
    "    W = tf.get_variable(\"W\", shape=[HU_decoder, input_shape[1]],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    b = tf.get_variable(\"b\", shape=[input_shape[1]])\n",
    "    \n",
    "    out = tf.nn.elu(tf.matmul(dec, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create loss function\n",
    "loss = tf.reduce_mean(tf.square(input_X - out))\n",
    "\n",
    "# create parameter update expressions\n",
    "lr = tf.Variable(1e-3, dtype=tf.float32, name='lr')\n",
    "optimizer = tf.train.AdamOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, batchsize, show=False):\n",
    "    if show:\n",
    "        for _ in tqdm.tqdm(range(0, inputs.num_examples, batchsize)):\n",
    "            yield inputs.next_batch(batchsize)[0]\n",
    "    else:\n",
    "        for _ in range(0, inputs.num_examples, batchsize):\n",
    "            yield inputs.next_batch(batchsize)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = tf.Variable(True)\n",
    "\n",
    "if train:\n",
    "    epsilon = tf.random_normal([1], name=\"epsilon\")\n",
    "else:\n",
    "    epsilon = tf.Variable(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(epsilon, feed_dict={train: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train your autoencoder\n",
    "# visualize progress in reconstruction and loss decay\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch %d' % (epoch + 1))\n",
    "    total_loss = 0.\n",
    "    iters = 0\n",
    "    for x in iterate_minibatches(mnist.train, 128, show=True):\n",
    "        _, c = sess.run([optimizer, loss], feed_dict={input_X: x})\n",
    "        total_loss += c\n",
    "        iters += 1\n",
    "    print('Average loss on train: %.3f' % (total_loss / iters))\n",
    "    total_loss = 0.\n",
    "    iters = 0\n",
    "    for x in iterate_minibatches(mnist.test, 128):\n",
    "        _, c = sess.run([optimizer, loss], feed_dict={input_X: x})\n",
    "        total_loss += c\n",
    "        iters += 1\n",
    "    print('Average loss on test: %.3f' % (total_loss / iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = mnist.test.images[:1]\n",
    "pred = sess.run(out, feed_dict={input_X: image})\n",
    "plot_gallery([image, pred], image_h, image_w, n_row=1, n_col=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_ = np.random.normal(scale=1e-2, size = [1, dimZ])\n",
    "image = sess.run(out, feed_dict={z: z_})\n",
    "plot_gallery([image], image_h, image_w, n_row=1, n_col=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian approach in deep learning considers everything in terms of distributions. Now our encoder generates not just a vector $z$ but posterior ditribution q(z|x). Technically, the first difference is that you need to split bottleneck layer in two. One dense layer will generate vector $\\mu$, and another will generate vector $\\sigma$. Below you can see the example how to implement the reparametrization trick:\n",
    "\n",
    "```python\n",
    "with tf.name_scope(\"sample_gaussian\"):\n",
    "    # reparameterization trick\n",
    "    epsilon = tf.random_normal(tf.shape(log_sigma), name=\"epsilon\")\n",
    "    return mu + epsilon * tf.exp(log_sigma) # N(mu, sigma**2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our decoder is also a function that generates distribution, we need to do the same splitting for output layer. When testing the model we will look only on mean values, so one of the output will be actual autoencoder output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we only ask for implementation of the simplest version of VAE - one $z$ sample per input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to compare with conventional AE, keep these hyperparameters\n",
    "# or change them for the values that you used before\n",
    "\n",
    "HU_encoder = 600\n",
    "HU_decoder = 600\n",
    "dimZ = 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the last, but not least! Place in the code where the most of the formulaes goes to - optimization objective. The objective for VAE has it's own name - variational lowerbound. And as for any lowerbound our intention is to maximize it. Here it is (for one sample $z$ per input $x$):\n",
    "\n",
    "$$\\mathcal{L} = -KL(q_{\\phi}(z|x)||p(z)) + \\log p_{\\theta}(x|z)$$\n",
    "\n",
    "Your next task is to implement two functions that compute KL-divergence and the second term - log-likelihood of an output. Here is some necessary math for your convenience:\n",
    "\n",
    "$$KL(q_\\phi(z|x)|p(z)) = -\\frac{1}{2}\\sum_{i=1}^{dimZ}(1+log(\\sigma_i^2)-\\mu_i^2-\\sigma_i^2)$$\n",
    "$$\\log p_{\\theta}(x|z) = \\sum_{i=1}^{dimX}\\log p_{\\theta}(x_i|z)=\\sum_{i=1}^{dimX} \\log \\Big( \\frac{1}{\\sigma_i\\sqrt{2\\pi}}e^{-\\frac{(\\mu_I-x)^2}{2\\sigma_i^2}} \\Big)=...$$\n",
    "\n",
    "Don't forget in the code that you are using $\\log\\sigma$ as variable. Explain, why not $\\sigma$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def KL_divergence(mu, logsigma):\n",
    "    return 0\n",
    "\n",
    "def log_likelihood(x, mu, logsigma):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the loss and training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create prediction variable\n",
    "# prediction =\n",
    "\n",
    "# create loss function\n",
    "# ...\n",
    "# loss = KL_divergence(..., ...) - log_likelihood(..., ..., ...)\n",
    "\n",
    "# create parameter update expressions\n",
    "# optimizer = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train your autoencoder\n",
    "# visualize progress in reconstruction and loss decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoder with normalizing flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original paper: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try to complicate our model with help of normalizing flows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"normflows.png\" alt=\"Normalizing flows\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(\\mathbf{z}) = \\mathbf{z} + \\mathbf{u}h(\\mathbf{w}^T\\mathbf{z} + b)$$\n",
    "$$|\\det \\frac{\\partial f}{\\partial \\mathbf{z}}| = |1 + \\mathbf{u}^Th'(\\mathbf{w}^T\\mathbf{z} + b)\\mathbf{w}|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower bound in this case looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathcal{L} = \\log p(x, z_k) - \\log q_0(z_0) + \\sum_{k = 1}^K \\log |1 + u_k^Th'(w_k^Tz_{k-1} + b)w_k|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
